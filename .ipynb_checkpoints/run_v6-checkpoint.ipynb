{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [12/Nov/2020 19:20:25] \"\u001b[37mPOST /sms HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request\n",
    "from twilio.twiml.messaging_response import MessagingResponse\n",
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import validators\n",
    "from newsapi import NewsApiClient\n",
    "from googleapiclient.discovery import build\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from summa.summarizer import summarize\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "with open('model.pickle', 'rb') as mod:\n",
    "    model = pickle.load(mod)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    return \"Online\"\n",
    "\n",
    "@app.route('/sms', methods=['POST'])\n",
    "def bot():\n",
    "    incoming_msg = request.values.get('Body', '')\n",
    "    \n",
    "    resp = MessagingResponse()\n",
    "    msg = resp.message()\n",
    "    responded = False\n",
    "    \n",
    "    if 'Menu' in incoming_msg or 'menu' in incoming_msg:\n",
    "        text = 'Hi Hello ! \\n This is Jazzy - A News Detection Bot \\n I am capable of doing some Tasks! \\n Type a Number to navigate: \\n 1.Article checking \\n 2.Article Summarization \\n 3.Facts checking \\n 4.Url Expander \\n Share me \\n https://wa.me/+14155238886?text=\"join came-poor\" '\n",
    "        msg.body(text)\n",
    "        responded = True\n",
    "        \n",
    "    if 'Commands' in incoming_msg or 'commands' in incoming_msg:\n",
    "        text = 'List of commands:\\n/AC - Article Checker\\n/AS - Article Summarizer\\n/FC - Facts Checker\\n/UE - URL Expander'\n",
    "        msg.body(text)\n",
    "        responded = True\n",
    "        \n",
    "    if '/AC ' in incoming_msg:\n",
    "        \n",
    "        msg1 = incoming_msg[4:]\n",
    "        valid = validators.url(msg1)\n",
    "        if valid == True:\n",
    "            my_url = msg1\n",
    "            try:\n",
    "                req = Request(my_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "                uClient = urlopen(req)\n",
    "            except:\n",
    "                uClient = urlopen(my_url)\n",
    "            page_html = uClient.read()\n",
    "            uClient.close()\n",
    "            page_soup = soup(page_html, 'html.parser')\n",
    "            title = page_soup.h1.text\n",
    "            \n",
    "            newsapi = NewsApiClient(api_key='cc8998f479954041b5f845f0b4491050')\n",
    "            news_sources = newsapi.get_sources()\n",
    "            top_headlines = newsapi.get_top_headlines(q=title, language='en', )\n",
    "            all_articles = newsapi.get_everything(q=title, language='en', )\n",
    "\n",
    "            source2 = []\n",
    "            description2 = []\n",
    "            if( (len(top_headlines['articles']) is not []) and (len(all_articles['articles']) is not []) ):\n",
    "                for article in all_articles['articles']:\n",
    "                    source2.append(article['source']['name'])\n",
    "                    description2.append(article['description'])\n",
    "#                 msg.body('The news is REAL\\n')\n",
    "#                 msg.body('\\nSource: '+ source2[0] + '\\n')\n",
    "#                 msg.body('Description: ' + description2[0])\n",
    "                msg.body('The news is REAL \\n' + 'Source: ' + source2[0] + '\\n' + 'Description: ' + description2[0])\n",
    "            else:\n",
    "                pred = model.predict([title])\n",
    "                ans = \"The news is mostly \" + pred[0]\n",
    "                msg.body(ans)\n",
    "\n",
    "\n",
    "        else:\n",
    "            msg.body(\"The URL does not exists !\")\n",
    "        \n",
    "        responded = True\n",
    "    \n",
    "    if '/AS' in incoming_msg:\n",
    "        msg2 = incoming_msg[4:]\n",
    "        my_url = msg2\n",
    "        try:\n",
    "            req = Request(my_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            uClient = urlopen(req)\n",
    "        except:\n",
    "            uClient = urlopen(my_url)\n",
    "        page_html = uClient.read()\n",
    "        uClient.close()\n",
    "        page_soup = soup(page_html,'html.parser')\n",
    "\n",
    "        article_text =' '.join(map(lambda p: p.text,page_soup.find_all('p')))\n",
    "\n",
    "        ans = summarize(article_text,ratio=0.2)\n",
    "        msg.body('Summarized article:\\n' + ans)\n",
    "        responded = True  \n",
    "        \n",
    "    if '/FC' in incoming_msg:\n",
    "        msg3 = incoming_msg[4:]\n",
    "        list_of_stopwords = list(stopwords.words('english'))\n",
    "        tokenized_text = word_tokenize(msg3)\n",
    "        clean_msg = ''\n",
    "        for word in tokenized_text:\n",
    "            word = word.lower()\n",
    "            if not word in list_of_stopwords and word != '.' and word != \"''\" and word != \"``\" and word != ']' and word != '!' and word != '%' and word != '&' and word != '?' and word != '//' and word != ';' and word != '|' and word != ' ' and word != \"'\" and word != '\"' and word != '[' and word != '@' and word != ',' and word != '#' and word != '..' and word != '-' and word != '(' and word != ')' and word != '...' and word != '/' and word != ':':\n",
    "                clean_msg += word + ' '\n",
    "\n",
    "        API_KEY = 'AIzaSyBEbc15F1s35_bgvC8eupXt0MpGkV92PnA'\n",
    "        SERVICE = build(\"factchecktools\", \"v1alpha1\", developerKey=API_KEY)\n",
    "        userQuery = clean_msg\n",
    "        request1 = SERVICE.claims().search(query=userQuery)\n",
    "        response = request1.execute()\n",
    "\n",
    "\n",
    "        if not bool(response):\n",
    "\n",
    "            source1 = []\n",
    "            description1 = []\n",
    "            newsapi = NewsApiClient(api_key='cc8998f479954041b5f845f0b4491050')\n",
    "            news_sources = newsapi.get_sources()\n",
    "            query = msg3\n",
    "            tokenized_text1 = word_tokenize(query)\n",
    "            word_count = len(tokenized_text1)\n",
    "            clean_msg1 = ''\n",
    "            count = 0\n",
    "            for word in tokenized_text1:\n",
    "                word = word.lower()\n",
    "                if not word in list_of_stopwords and word != '.' and word != \"''\" and word != \"``\" and word != ']' and word != '!' and word != '%' and word != '&' and word != '?' and word != '//' and word != ';' and word != '|' and word != ' ' and word != \"'\" and word != '\"' and word != '[' and word != '@' and word != ',' and word != '#' and word != '..' and word != '-' and word != '(' and word != ')' and word != '...' and word != '/' and word != ':':\n",
    "                    clean_msg1 += word + ' '\n",
    "            all_articles = newsapi.get_everything(q=clean_msg1, sort_by='relevancy', language='en', )\n",
    "\n",
    "            if (all_articles['articles'] !=[]):\n",
    "                for article in all_articles['articles']:\n",
    "                    source1.append(article['source']['name'])\n",
    "                    description1.append(article['description'])\n",
    "                    \n",
    "                for i in range(len(source1)):\n",
    "                    for j in range(word_count):\n",
    "                        if (tokenized_text1[j] in description1[i]):\n",
    "                            count = count + 1;\n",
    "                            if (count >= (word_count / 2)+1):\n",
    "                                break\n",
    "                \n",
    "            if (count >= (word_count / 2)+1):\n",
    "#                             msg.body('*news api part*')\n",
    "#                             msg.body('The news is REAL')\n",
    "#                             msg.body(source1[i])\n",
    "#                             msg.body(description1[i])\n",
    "                            msg.body('The news is REAL \\n' + 'Source: ' + source1[i] + '\\n' + 'Description: ' + description1[i] + '\\n')\n",
    "                                \n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "#             result = response['claims'][0]['claimReview'][0]['textualRating']\n",
    "#             website = response['claims'][0]['claimReview'][0]['publisher']['name']\n",
    "#             url = response['claims'][0]['claimReview'][0]['url']\n",
    "#             msg.body('*facts api part*')\n",
    "#             msg.body(result)\n",
    "#             msg.body(website)\n",
    "#             msg.body(url)\n",
    "#             msg.body('Related claims: \\n' + 'Claim: ' + result + '\\n' + 'Source: ' + website + '\\n' + 'Article link: ' + url + '\\n')\n",
    "            resp.message(\"Related claims:\\n\\n\")\n",
    "            for i in range(len(response['claims'])):\n",
    "                claim_text = response['claims'][i]['text']\n",
    "                result = response['claims'][i]['claimReview'][0]['textualRating']\n",
    "                website = response['claims'][i]['claimReview'][0]['publisher']['name']\n",
    "                url = response['claims'][i]['claimReview'][0]['url']\n",
    "                factsapi_answer = 'Claim : ' + claim_text + '\\n' + 'Rating: ' + result + '\\n' + 'Source: ' + website + '\\n' + 'Article link: ' + url + '\\n'\n",
    "                msg.body(factsapi_answer)\n",
    "    \n",
    "        temp = msg3.split()\n",
    "        word_count1 = len(temp)\n",
    "        processed_text = '+'.join(temp)\n",
    "\n",
    "        my_url = f'https://www.google.com/search?q={processed_text}'\n",
    "        req = Request(my_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        uClient = urlopen(req)\n",
    "        page_html = uClient.read()\n",
    "        uClient.close()\n",
    "        page_soup = soup(page_html, 'html.parser')\n",
    "\n",
    "        container = page_soup.find_all('div', {'class': 'BNeawe s3v9rd AP7Wnd'})\n",
    "\n",
    "        list_of_stopwords = list(stopwords.words('english'))\n",
    "        tokenized_user_text = word_tokenize(msg3)\n",
    "        clean_user_text = []\n",
    "        for word in tokenized_user_text:\n",
    "            word = word.lower()\n",
    "            if not word in list_of_stopwords and word != '.' and word != \"''\" and word != \"``\" and word != ']' and word != '!' and word != '%' and word != '&' and word != '?' and word != '//' and word != ';' and word != '|' and word != ' ' and word != \"'\" and word != '\"' and word != '[' and word != '@' and word != ',' and word != '#' and word != '..' and word != '-' and word != '(' and word != ')' and word != '...' and word != '/' and word != ':':\n",
    "                clean_user_text.append(word)\n",
    "\n",
    "        for i in range(len(container)):\n",
    "            tokenized_result = word_tokenize(container[i].text)\n",
    "            clean_result = ''\n",
    "            clean_searches = []\n",
    "            for word in tokenized_user_text:\n",
    "                word = word.lower()\n",
    "                if not word in list_of_stopwords and word != '.' and word != \"''\" and word != \"``\" and word != ']' and word != '!' and word != '%' and word != '&' and word != '?' and word != '//' and word != ';' and word != '|' and word != ' ' and word != \"'\" and word != '\"' and word != '[' and word != '@' and word != ',' and word != '#' and word != '..' and word != '-' and word != '(' and word != ')' and word != '...' and word != '/' and word != ':':\n",
    "                    clean_result = word + ' '\n",
    "                    clean_searches.append(clean_result)\n",
    "\n",
    "        count1 = 0\n",
    "        for i in range(len(clean_searches)):\n",
    "            for j in range(len(clean_user_text)):\n",
    "                if (clean_user_text[j] in clean_searches[i]):\n",
    "                    count1 = count1 + 1;\n",
    "                if (count1 >= word_count1 / 2):\n",
    "                    break\n",
    "                    \n",
    "        if (count1 >= word_count1 / 2):          \n",
    "#             msg.body('*google search part*')\n",
    "#             msg.body(container[0].text)\n",
    "            resp.message('\\nMore info regarding the claim: \\n' + container[0].text)\n",
    "\n",
    "    \n",
    "        responded = True\n",
    "            \n",
    "    if '/UE' in incoming_msg:\n",
    "        msg4 = incoming_msg[4:]\n",
    "        valid = validators.url(msg4)\n",
    "        \n",
    "        if valid == True:\n",
    "            shortened_url = msg4\n",
    "            my_url = f'https://checkshorturl.com/expand.php?u={shortened_url}' \n",
    "            req = Request(my_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            uClient = urlopen(req)\n",
    "            page_html = uClient.read()\n",
    "            uClient.close()\n",
    "            page_soup = soup(page_html,'html.parser')\n",
    "\n",
    "            content = page_soup.find_all('tr')\n",
    "            long_url = content[0].text\n",
    "            content_title = content[6].text\n",
    "            content_description = content[7].text\n",
    "#             msg.body(long_url)\n",
    "#             msg.body(title)\n",
    "#             msg.body(description)\n",
    "            msg.body(long_url + '\\n' + 'Title: ' + content_title + '\\n' + 'Description: ' + content_description)\n",
    "        else:\n",
    "            msg.body(\"The URL does not exists !\")\n",
    "        \n",
    "        responded = True\n",
    "\n",
    "\n",
    "    if responded == False:\n",
    "        msg.body('no commands found')\n",
    "\n",
    "    return str(resp)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
