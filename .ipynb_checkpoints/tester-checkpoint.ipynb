{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r ML_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'REAL'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = 'SPB dude died due to health issues'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_stopwords = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = word_tokenize(msg)\n",
    "clean_msg = ''\n",
    "for word in tokenized_text:\n",
    "        word = word.lower()\n",
    "        if not word in list_of_stopwords and word != '.' and word != \"''\" and word!=\"``\"and word !=']' and word !='!' and word !='%' and word !='&' and word !='?' and word !='//' and word !=';' and word !='|' and word != ' ' and word != \"'\" and word !='\"' and  word !='[' and word != '@' and word != ',' and word !='#' and word !='..' and word !='-' and word !='(' and word !=')' and word != '...' and word != '/' and word !=':':\n",
    "            clean_msg += word + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spb dude died due health issues '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            list_of_stopwords = list(stopwords.words('english'))\n",
    "            tokenized_text = word_tokenize(msg)\n",
    "            clean_msg = ''\n",
    "            for word in tokenized_text:\n",
    "                word = word.lower()\n",
    "                if not word in list_of_stopwords and word != '.' and word != \"''\" and word!=\"``\"and word !=']' and word !='!' and word !='%' and word !='&' and word !='?' and word !='//' and word !=';' and word !='|' and word != ' ' and word != \"'\" and word !='\"' and  word !='[' and word != '@' and word != ',' and word !='#' and word !='..' and word !='-' and word !='(' and word !=')' and word != '...' and word != '/' and word !=':':\n",
    "                    clean_msg += word + ' '\n",
    "                    \n",
    "                    \n",
    "            #news api part        \n",
    "            source1 = []\n",
    "            description1 = []\n",
    "            newsapi = NewsApiClient(api_key='cc8998f479954041b5f845f0b4491050')\n",
    "            news_sources = newsapi.get_sources()\n",
    "            all_articles = newsapi.get_everything(q = clean_msg, language = 'en',)\n",
    "            for article in all_articles['articles']:\n",
    "                source1.append(article['source']['name'])\n",
    "                description1.append(article['description'])\n",
    "\n",
    "\n",
    "            if(all_articles['articles'] == []):\n",
    "\n",
    "                API_KEY='AIzaSyBEbc15F1s35_bgvC8eupXt0MpGkV92PnA'\n",
    "                SERVICE=build(\"factchecktools\",\"v1alpha1\",developerKey=API_KEY)\n",
    "                userQuery=clean_msg\n",
    "\n",
    "                request1=SERVICE.claims().search(query=userQuery)\n",
    "                response=request1.execute()\n",
    "                \n",
    "                if bool(response):\n",
    "                    result  = response['claims'][0]['claimReview'][0]['textualRating']\n",
    "                    website = response['claims'][0]['claimReview'][0]['publisher']['name']\n",
    "                    url = response['claims'][0]['claimReview'][0]['url']\n",
    "                    resp.message(result)\n",
    "                    resp.message(website)\n",
    "                    resp.message(url)\n",
    "                    \n",
    "                else:\n",
    "                    resp.message(\"The news is FAKE\")\n",
    "                \n",
    "            else:\n",
    "                resp.message('The news is REAL')\n",
    "                resp.message(source1[0])\n",
    "                resp.message(description1[0])   \n",
    "                    \n",
    "            \n",
    "           \n",
    "\n",
    "\n",
    "            \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "            else:\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
